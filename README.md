# ğŸ“‚ Multimodal_RAG_SupplementaryFiles_2025

This repository contains all supplementary materials for the research project:  
**"Multimodal RAG Application with AI Observability and Document Intelligence"**, including:
- ğŸ–¼ï¸ Static and dynamic architecture diagrams
- ğŸ¥ Demo video of the system
- ğŸ“„ Published IJIRT paper (2024)

---

## ğŸ“– Project Summary

This project presents a dual-model GenAI framework combining **Retrieval-Augmented Generation (RAG)** with **multimodal input handling** and **AI observability**. It supports text, image (OCR), PDF, and URL inputs, and integrates tools like **LangChain**, **CrewAI**, **Gemini API**, **Qdrant**, and **Arize Phoenix**.

Two models were developed:
- **Studently.ai** (private, Streamlit-based academic tool)
- **SASAi** (open-source, Vercel-based JavaScript deployment)

---

## ğŸ–¼ï¸ Diagrams & Visualizations

### Fig. 1 â€” System Evolution Diagram (Static)

> **Dynamic View:**  
> *Evolution of system architecture from the basic SASAi v1 to the upgraded Multimodal RAG Application.*  
> ğŸ”— [View Interactive Diagram](https://abs-14.github.io/Multimodal_RAG_SupplementaryFiles_2025/evolution_architecture.html)

### Fig. 2 â€” Studently.ai Framework Architecture

---

## ğŸ¥ Project Demo Video

> *Recorded demonstration of the Studently.ai application with real-time document Q&A and resume parsing.*

[â–¶ Watch Demo Video](./media/Multimodal_RAG.mp4)

> *(If playback doesn't work, download and play locally â€” or request a YouTube-hosted link)*

---

## ğŸ“„ Published Paper (IJIRT - First Phase)

**Title:** *AI Observability-Driven Multimodal RAG Application for Document Intelligence*  
ğŸ“¥ [Download PDF]([./docs/Published_IJIRT_Paper_2024.pdf](https://github.com/ABS-14/Multimodal_RAG_SupplementaryFiles_2025/blob/main/RAG_Multimodel_ResearchPaper_IJSRET.pdf))

> Published in: **International Journal of Innovative Research in Technology (IJIRT)**  
> Issue: Vol. 11, Issue 4, April 2024

---

## ğŸ“ Folder Structure

