# 📂 Multimodal_RAG_SupplementaryFiles_2025

This repository contains all supplementary materials for the research project:  
**"Multimodal RAG Application with AI Observability and Document Intelligence"**, including:
- 🖼️ Static and dynamic architecture diagrams
- 🎥 Demo video of the system
- 📄 Published IJIRT paper (2024)

---

## 📖 Project Summary

This project presents a dual-model GenAI framework combining **Retrieval-Augmented Generation (RAG)** with **multimodal input handling** and **AI observability**. It supports text, image (OCR), PDF, and URL inputs, and integrates tools like **LangChain**, **CrewAI**, **Gemini API**, **Qdrant**, and **Arize Phoenix**.

Two models were developed:
- **Studently.ai** (private, Streamlit-based academic tool)
- **SASAi** (open-source, Vercel-based JavaScript deployment)

---

## 🖼️ Diagrams & Visualizations

### Fig. 1 — System Evolution Diagram (Static)

> **Dynamic View:**  
> *Evolution of system architecture from the basic SASAi v1 to the upgraded Multimodal RAG Application.*  
> 🔗 [View Interactive Diagram](https://abs-14.github.io/Multimodal_RAG_SupplementaryFiles_2025/evolution_architecture.html)

### Fig. 2 — Studently.ai Framework Architecture

---

## 🎥 Project Demo Video

> *Recorded demonstration of the Studently.ai application with real-time document Q&A and resume parsing.*

[▶ Watch Demo Video](./media/Multimodal_RAG.mp4)

> *(If playback doesn't work, download and play locally — or request a YouTube-hosted link)*

---

## 📄 Published Paper (IJSRET - First Phase)

**Title:** *AI Observability-Driven Multimodal RAG Application for Document Intelligence*  
📥 [Download PDF](https://github.com/ABS-14/Multimodal_RAG_SupplementaryFiles_2025/blob/main/RAG_Multimodel_ResearchPaper_IJSRET.pdf)

> Published in: **International Journal of Innovative Research in Technology (IJIRT)**  
> Issue: Vol. 11, Issue 4, April 2024

---


